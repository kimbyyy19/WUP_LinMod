---
title: "linear model from Web"
author: "kimberly Lemus Munoz"
date: "summer 2022"
output:
   html_document:
         toc: true
         toc_depth: 5
        
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Read about the data from the website where it is staged.  Then form three regression models; Model1 is SIMS~ARM, Model2 is SIMS~GRIP, and Model3 is SIMS~ARM+GRIP. For each model find a 95% prediction interval of SIMS given a value of 94  for GRIP and 88 for ARM. Compare Model1 with Model3 using anova. Write it up in a markdown document, push the project up to your github account and submit it back to canvas as link. 

 


```{r include=FALSE}
require(tidyverse)
require(tigerstats)
require(rgl)
require(knitr)

```

```{r}
data <- read.csv(file="https://onlinestatbook.com/case_studies_rvls/physical_strength/data.txt",sep="",header=TRUE)  

```

## Model 1 SIM~ARMS

### scatterplot

```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=ARM))
basicNN + geom_point()
```


The scatterplot looks as if the points are going uphill to the right. My suspicion is that this plot is a positive correlation due to the fact that the scatterplot is going uphill to the right.


### Numerical results


```{r}
cor(SIMS~ARM,data=data)
```
The value above provides the specific correlation coefficient on the relationship between SIMS and ARM. The value 0.686 is quite decent in showing the positive linear relationship between SIMS and ARM. 




### Inferential  (Build model.1)


```{r}
model.1 <- lm(SIMS~ARM,data=data)
summary.lm(model.1)
```

The equation of a line is y=mx+b.
When we  fit the equation of the line equation is SIMS= -4.095160 + 0.054563*ARM.

The model above shows the linear model of the relationship between SIMS and ARM. The most important information that can be taken from the model are the residual standard error and the adjusted R-squared value. A low residual standard error value of 1.226 means that the values do not deviate largely from the predicted value. Moreover, based on the value of the adjusted R-squared, we're reducing the error from the mean model by 46.6 %. 


#### Predict at target point
```{r}
Targetpoint <- data.frame(ARM= 88, GRIP = 94)
```

```{r}
predict(model.1 , Targetpoint, interval = "prediction")
```

This predicted the value we would get from model 1 if the target point for ARM is 88 and Grip is 94. But given that this model only makes use of ARM, it disregards the targetpoint value for GRIP. 











#### scatterplot with model fit
 
```{r}
basicNN + geom_point() + geom_lm()
```



The scatter plot above now includes the prediction line that was determined previously. It further establishes that the relationship creates a normal distribution wherein the 95% of all the point is within two residual values from the line of best fit.  
 







## Model 2 SIM~GRIP


### Now add in scatterplot


```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=GRIP))
basicNN + geom_point() + geom_smooth(method=lm)
```


Here is the result of the scatterplot and our best fit line for our GRIP and SIMS data. If we use our prediction value, it matches x-value = 0.94 for GRIP.




### Numerical results 

```{r}
cor(SIMS~GRIP,data=data)
```
The value above provides the specific correlation coefficient on the relationship between SIMS and GRIP. Although a value of 0.640 is quite decent in showing the positive linear relationship between SIMS and GRIP, it is lower than that of the first model. Therefore, it points toward the idea that arm strength is a better variable in predicting a worker's performance in the simulations. 






### Inferential  (Build model.2)
  
```{r}
model.2 <- lm(SIMS~ARM+GRIP,data=data)
summary.lm(model.2)
```  

Fit equation is SIMS=-5.43 + GRIP * 0.02 + ARM * 0.04

Above is the linear model of the relationship between SIMS and GRIP, and it also shows the standard residual error value and the adjusted R-squared. Comparing these two values from the those of the first model, we can expect that the standard deviation curve is wider on this model compared to the first one. Also, the adjusted R-squared value on this model means that we're able to reduce the error from the mean model by 40.53% which is lower than that of the first model. Lastly, more of the error is explained by the first model compared to the second model, based on the residual standard error value.

#### predict model.2 at target point

```{r}
predict(model.2 , Targetpoint, interval = "prediction")
```


#### now add the model fit to our plot for model.2
  
```{r}
basicNN_GRIP + geom_point() + geom_lm()
```
The scatter plot above combined the original data and the predicted values for SIMS~GRIP. Given all the information previously determined, this model, specifically grip strength, is not as reliable as arm strength in predicting a worker's performance in the simulations.

## Model 3 SIM~ARM+GRIP


### Numerical results (cor)
```{r}
cor(SIMS~ARM+GRIP,data=data)
```
The value of the correlation coefficient of the third model is higher than those of the previous two. This indicates that this model may be better than the first two models, but further tests can be done to confirm this. 

  
### Inferential  (Build 2-dimentional model.3)

```{r}
model.3 <- lm(SIMS~ARM+GRIP,data=data)
summary.lm(model.3)
```


The model above shows the relationship of SIMS and ARM and GRIP combined. Based on the residual standard error and adjusted r-squared values, this model appears to be better than the first two models. The residual standard error is smaller on this model than the two previous ones which means that the standard deviation curve would be narrower. Also, the adjusted R-squared value is higher compared to that of the first two models which means that this model was able to reduce 53.58% of error from the mean model. This is significantly better than that of model 1 and model 2. 


#### predict model.3 at target point

```{r}
predict(model.3 , Targetpoint, interval = "prediction")
```  

## Comparing nested models ANOVA Test

### Model.1 vs Model.3

```{r}
anova(model.1, model.3)
```
The anova test above shows that model 1 has a residual standard error of 217.88 while model 3 has 188.43. This indicates that model 3 reduced the residual standard error of model 1 by 29.45, and according to the p-value, this difference is statistically significant. Therefore, we can confirm that model 3 is better than model 1. 





### Model.2 vs Model.3
```{r}
anova(model.2, model.3)
```

The anova test above shows that model 2 has a residual standard error of 243.07 while model 3 has 188.43. This indicates that model 3 reduced the residual standard error of model 2 by 54.639, and according to the p-value, this difference is statistically significant. Therefore, we can confirm that model 3 is better than model 2. 

## Informally compare Model.1 with model.2
## Informally compare Model.1 with model.2

```{r}
anova(model.2, model.1)
```

The anova test above base the order of models depending on which models got inputted first on the code. As a result, number 1 is actually model 2 while number 2 is actually model 1. This is done so that the difference in RSS would be positive number. Meanwhile, we can infer from the anova test above that whichever model has a lower RSS value would be the better model. In this case, number 2, which is actually model 1, is better than model 2. 


